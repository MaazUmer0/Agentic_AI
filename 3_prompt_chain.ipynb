{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515b65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qa(TypedDict):\n",
    "    topic:str\n",
    "    outline:str\n",
    "    content:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ceab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph= StateGraph(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c42dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outline(state: qa) -> qa:\n",
    "    #fetch topic\n",
    "    topic = state['title']\n",
    "    \n",
    "    #make prompt\n",
    "    prompt = f'make outline for this topic - {topic}'\n",
    "    outline = model.invoke(prompt).content\n",
    "    \n",
    "    #create outline\n",
    "    state['outline'] = outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81781b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blog(state: qa) -> qa:\n",
    "    #fetch outline\n",
    "    outline = state['outline']\n",
    "    \n",
    "    #make prompt\n",
    "    prompt = f'write a blog post based on this outline - {outline}'\n",
    "    content = model.invoke(prompt).content\n",
    "    \n",
    "    #create blog\n",
    "    state['content'] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node('create outline', create_outline)\n",
    "graph.add_node('create blog', create_blog)\n",
    "graph.add_edge(START, 'create outline')\n",
    "graph.add_edge('create outline', 'create blog')\n",
    "graph.add_edge('create blog', END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = graph.compile()\n",
    "initial_state: qa = {'topic': 'The future of AI in healthcare', 'outline': '', 'content': ''}\n",
    "final_state = workflow(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185d78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a309b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
